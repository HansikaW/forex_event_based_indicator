{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lahiru\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (1,2,3,4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2013.12.05 03:00:00'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None  #  no important. This is for avoiding the warning of chained assignments\n",
    "\n",
    "drop_cols = ['c','D','E','F','G','I','J'] \n",
    "\n",
    "JPY_USD_df = pd.read_csv('USDJPY-2000-2020-15m.csv') #AUS_USD CURRENCY DATA SET\n",
    "JPY_USD_df = JPY_USD_df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE']]\n",
    "\n",
    "\n",
    "# import all the event files, variable name tells what is the event\n",
    "#use 'parse_dates' keyword ynside the 'read_csv' function in order to combine date and time also convert the data type into 'datetime64'\n",
    "JPY_GDP_df = pd.read_csv('JPY_GDP.csv',header = None,names =['DATE','TIME','c','D','E','F','G','JPY_GDP','I','J'] ,parse_dates= [[0,1]]) \n",
    "JPY_GDP_df =JPY_GDP_df.drop(columns=drop_cols)\n",
    "\n",
    "\n",
    "JPY_PPI_df = pd.read_csv('JPY_PPI.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','JPY_PPI','I','J'],parse_dates= [[0,1]]).dropna()\n",
    "JPY_PPI_df = JPY_PPI_df.drop(columns=drop_cols)\n",
    "JPY_PPI_df['DATE_TIME'] = pd.to_datetime(JPY_PPI_df['DATE_TIME'])\n",
    "\n",
    "JPY_RETAILSALES_df = pd.read_csv('JPY_RETAILSALES.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','JPY_RETAILSALES','I','J'],parse_dates= [[0,1]])\n",
    "JPY_RETAILSALES_df = JPY_RETAILSALES_df.drop(columns=drop_cols)\n",
    "\n",
    "JPY_UNEMP_df = pd.read_csv('JPY_UNEP.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','JPY_UNEMP','I','J'],parse_dates= [[0,1]])\n",
    "JPY_UNEMP_df = JPY_UNEMP_df.drop(columns=drop_cols)\n",
    "\n",
    "JPY_CPI_df = pd.read_csv('JPY_CPI.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','JPY_CPI','I','J'],parse_dates= [[0,1]]).dropna()\n",
    "JPY_CPI_df = JPY_CPI_df.drop(columns=drop_cols)\n",
    "JPY_CPI_df['DATE_TIME'] = pd.to_datetime(JPY_CPI_df['DATE_TIME'])\n",
    "\n",
    "JPY_IR_df = pd.read_csv('JPY_IR.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','JPY_IR','I','J'],parse_dates= [[0,1]]).dropna()\n",
    "JPY_IR_df = JPY_IR_df.drop(columns=drop_cols)\n",
    "JPY_IR_df['DATE_TIME'] = pd.to_datetime(JPY_IR_df['DATE_TIME'])\n",
    "\n",
    "USD_CPI_df = pd.read_csv('USD_CPI.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_CPI','I','J'],parse_dates= [[0,1]])\n",
    "USD_CPI_df = USD_CPI_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_GDP_df = pd.read_csv('USD_GDP.csv',header = None,names =['DATE','TIME','c','D','E','F','G','USD_GDP','I','J'],parse_dates= [[0,1]]).dropna()\n",
    "USD_GDP_df = USD_GDP_df.drop(columns=drop_cols)\n",
    "USD_GDP_df['DATE_TIME'] =pd.to_datetime(USD_GDP_df['DATE_TIME'])\n",
    "\n",
    "USD_IR_df = pd.read_csv('USD_IR.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_IR','I','J'],parse_dates= [[0,1]])\n",
    "USD_IR_df = USD_IR_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_PAYROLL_df = pd.read_csv('USD_PAYROLL.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_PAYROLL','I','J'],parse_dates= [[0,1]]).dropna()\n",
    "USD_PAYROLL_df = USD_PAYROLL_df.drop(columns=drop_cols)\n",
    "USD_PAYROLL_df['DATE_TIME'] = pd.to_datetime(USD_PAYROLL_df['DATE_TIME'] )\n",
    "USD_PAYROLL_df['USD_PAYROLL'] = (USD_PAYROLL_df['USD_PAYROLL'])/1000 \n",
    "\n",
    "\n",
    "USD_PPI_df = pd.read_csv('USD_PPI.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_PPI','I','J'],parse_dates= [[0,1]])\n",
    "USD_PPI_df = USD_PPI_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_RETAIL_df = pd.read_csv('USD_RETAIL.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_RETAIL','I','J'],parse_dates= [[0,1]]).dropna()\n",
    "USD_RETAIL_df = USD_RETAIL_df.drop(columns=drop_cols)\n",
    "USD_RETAIL_df['DATE_TIME'] = pd.to_datetime(USD_RETAIL_df['DATE_TIME'])\n",
    "\n",
    "USD_UNEMP_df = pd.read_csv('USD_UNEMP.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_UNEMP','I','J'],parse_dates= [[0,1]])\n",
    "USD_UNEMP_df = USD_UNEMP_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_PAYROLL_df['USD_PAYROLL']\n",
    "JPY_USD_df['DATE_TIME'][344732]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select the data from 2011-2020 from the 'AUD_USD_df' data set where the pips are located.\n",
    "\n",
    "d =JPY_USD_df.loc[272339:500240 ,:] \n",
    "\n",
    "\n",
    "df = d.reset_index(drop=True)\n",
    "\n",
    "#removing the rows including dates which are out of the format\n",
    "DATE_TIME = []            \n",
    "for i in df['DATE_TIME']:\n",
    "    if len(i)== 19:\n",
    "        if str(i) != '2013.12.05000000001' :\n",
    "            DATE_TIME.append(i)\n",
    "    \n",
    "x = pd.DataFrame(DATE_TIME, columns = ['DATE_TIME'])\n",
    "df = pd.merge(df,x,on = 'DATE_TIME',how ='right')\n",
    "df['DATE_TIME'] =pd.to_datetime(df['DATE_TIME'])\n",
    "\n",
    "df['EX_DATE_TIME'] = pd.to_datetime(df['DATE_TIME']) # convert the type to datetime\n",
    "df['DATE_TIME'] = df['EX_DATE_TIME']- pd.Timedelta(hours=7)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "df = df[df['HIGH'] != \"73 04:00:00\"]\n",
    "df = df[df['HIGH'] != \"97.848999999999.79\"]\n",
    "df = df[df['HIGH'] != \"120 03:15:00\"]\n",
    "df = df[df['OPEN'] != '107.628999999999.51100000000001']\n",
    "df = df[df['CLOSE'] != \"103.922000000000101.958\"]\n",
    "df = df[df['CLOSE'] != \":30:00\"]\n",
    "\n",
    "df['HIGH'] = pd.to_numeric(df['HIGH'])\n",
    "df['LOW'] = pd.to_numeric(df['LOW'])\n",
    "df['OPEN'] = pd.to_numeric(df['OPEN'])\n",
    "df['CLOSE'] = pd.to_numeric(df['CLOSE'])\n",
    "x =  datetime.datetime(2011,1,27, 18,30,0)\n",
    "(df['DATE_TIME'] == x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>JPY_GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-02-13 18:50:00</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-03-09 18:50:00</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-05-18 18:50:00</td>\n",
       "      <td>-0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-06-08 18:50:00</td>\n",
       "      <td>-0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2020-03-08 19:50:00</td>\n",
       "      <td>-1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2020-05-17 19:50:00</td>\n",
       "      <td>-0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2020-06-07 19:50:00</td>\n",
       "      <td>-0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2020-08-02 19:50:00</td>\n",
       "      <td>-0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2020-08-16 19:50:00</td>\n",
       "      <td>-7.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE_TIME  JPY_GDP\n",
       "0  2011-01-01 04:00:00      2.2\n",
       "1  2011-02-13 18:50:00     -0.3\n",
       "2  2011-03-09 18:50:00     -0.3\n",
       "3  2011-05-18 18:50:00     -0.9\n",
       "4  2011-06-08 18:50:00     -0.9\n",
       "..                 ...      ...\n",
       "76 2020-03-08 19:50:00     -1.8\n",
       "77 2020-05-17 19:50:00     -0.9\n",
       "78 2020-06-07 19:50:00     -0.6\n",
       "79 2020-08-02 19:50:00     -0.6\n",
       "80 2020-08-16 19:50:00     -7.8\n",
       "\n",
       "[81 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge all the dataframes (all the events of both countries and market prices by matching with the date and time values)\n",
    "new_df =  df.merge(JPY_GDP_df, on = 'DATE_TIME', how = 'left')\\\n",
    "          .merge(JPY_PPI_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(JPY_RETAILSALES_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(JPY_UNEMP_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(JPY_CPI_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(JPY_IR_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_PPI_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_CPI_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_GDP_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_IR_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_PAYROLL_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_RETAIL_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_UNEMP_df, on = 'DATE_TIME', how = 'left')\n",
    " \n",
    "      \n",
    "JPY_GDP_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>EX_DATE_TIME</th>\n",
       "      <th>JPY_GDP</th>\n",
       "      <th>JPY_PPI</th>\n",
       "      <th>JPY_RETAILSALES</th>\n",
       "      <th>JPY_UNEMP</th>\n",
       "      <th>JPY_CPI</th>\n",
       "      <th>JPY_IR</th>\n",
       "      <th>USD_PPI</th>\n",
       "      <th>USD_CPI</th>\n",
       "      <th>USD_GDP</th>\n",
       "      <th>USD_IR</th>\n",
       "      <th>USD_PAYROLL</th>\n",
       "      <th>USD_RETAIL</th>\n",
       "      <th>USD_UNEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-02 17:00:00</td>\n",
       "      <td>81.180</td>\n",
       "      <td>81.071</td>\n",
       "      <td>81.106</td>\n",
       "      <td>81.179</td>\n",
       "      <td>2011-01-03 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-02 17:15:00</td>\n",
       "      <td>81.226</td>\n",
       "      <td>81.139</td>\n",
       "      <td>81.179</td>\n",
       "      <td>81.225</td>\n",
       "      <td>2011-01-03 00:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-02 17:30:00</td>\n",
       "      <td>81.225</td>\n",
       "      <td>81.159</td>\n",
       "      <td>81.225</td>\n",
       "      <td>81.175</td>\n",
       "      <td>2011-01-03 00:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-02 17:45:00</td>\n",
       "      <td>81.184</td>\n",
       "      <td>81.109</td>\n",
       "      <td>81.175</td>\n",
       "      <td>81.122</td>\n",
       "      <td>2011-01-03 00:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-02 18:00:00</td>\n",
       "      <td>81.163</td>\n",
       "      <td>81.123</td>\n",
       "      <td>81.123</td>\n",
       "      <td>81.147</td>\n",
       "      <td>2011-01-03 01:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228256</th>\n",
       "      <td>2020-03-18 22:30:00</td>\n",
       "      <td>109.391</td>\n",
       "      <td>109.178</td>\n",
       "      <td>109.232</td>\n",
       "      <td>109.226</td>\n",
       "      <td>2020-03-19 05:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228257</th>\n",
       "      <td>2020-03-18 22:45:00</td>\n",
       "      <td>109.340</td>\n",
       "      <td>109.210</td>\n",
       "      <td>109.225</td>\n",
       "      <td>109.285</td>\n",
       "      <td>2020-03-19 05:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228258</th>\n",
       "      <td>2020-03-18 23:00:00</td>\n",
       "      <td>109.446</td>\n",
       "      <td>109.273</td>\n",
       "      <td>109.284</td>\n",
       "      <td>109.439</td>\n",
       "      <td>2020-03-19 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228259</th>\n",
       "      <td>2020-03-18 23:15:00</td>\n",
       "      <td>109.553</td>\n",
       "      <td>109.400</td>\n",
       "      <td>109.439</td>\n",
       "      <td>109.401</td>\n",
       "      <td>2020-03-19 06:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228260</th>\n",
       "      <td>2020-03-18 23:30:00</td>\n",
       "      <td>109.397</td>\n",
       "      <td>109.329</td>\n",
       "      <td>109.397</td>\n",
       "      <td>109.363</td>\n",
       "      <td>2020-03-19 06:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228261 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATE_TIME     HIGH      LOW     OPEN    CLOSE  \\\n",
       "0      2011-01-02 17:00:00   81.180   81.071   81.106   81.179   \n",
       "1      2011-01-02 17:15:00   81.226   81.139   81.179   81.225   \n",
       "2      2011-01-02 17:30:00   81.225   81.159   81.225   81.175   \n",
       "3      2011-01-02 17:45:00   81.184   81.109   81.175   81.122   \n",
       "4      2011-01-02 18:00:00   81.163   81.123   81.123   81.147   \n",
       "...                    ...      ...      ...      ...      ...   \n",
       "228256 2020-03-18 22:30:00  109.391  109.178  109.232  109.226   \n",
       "228257 2020-03-18 22:45:00  109.340  109.210  109.225  109.285   \n",
       "228258 2020-03-18 23:00:00  109.446  109.273  109.284  109.439   \n",
       "228259 2020-03-18 23:15:00  109.553  109.400  109.439  109.401   \n",
       "228260 2020-03-18 23:30:00  109.397  109.329  109.397  109.363   \n",
       "\n",
       "              EX_DATE_TIME  JPY_GDP  JPY_PPI  JPY_RETAILSALES  JPY_UNEMP  \\\n",
       "0      2011-01-03 00:00:00      NaN      NaN              NaN        NaN   \n",
       "1      2011-01-03 00:15:00      NaN      NaN              NaN        NaN   \n",
       "2      2011-01-03 00:30:00      NaN      NaN              NaN        NaN   \n",
       "3      2011-01-03 00:45:00      NaN      NaN              NaN        NaN   \n",
       "4      2011-01-03 01:00:00      NaN      NaN              NaN        NaN   \n",
       "...                    ...      ...      ...              ...        ...   \n",
       "228256 2020-03-19 05:30:00      NaN      NaN              NaN        NaN   \n",
       "228257 2020-03-19 05:45:00      NaN      NaN              NaN        NaN   \n",
       "228258 2020-03-19 06:00:00      NaN      NaN              NaN        NaN   \n",
       "228259 2020-03-19 06:15:00      NaN      NaN              NaN        NaN   \n",
       "228260 2020-03-19 06:30:00      NaN      NaN              NaN        NaN   \n",
       "\n",
       "        JPY_CPI  JPY_IR  USD_PPI  USD_CPI  USD_GDP  USD_IR  USD_PAYROLL  \\\n",
       "0           NaN     NaN      NaN      NaN      NaN     NaN          NaN   \n",
       "1           NaN     NaN      NaN      NaN      NaN     NaN          NaN   \n",
       "2           NaN     NaN      NaN      NaN      NaN     NaN          NaN   \n",
       "3           NaN     NaN      NaN      NaN      NaN     NaN          NaN   \n",
       "4           NaN     NaN      NaN      NaN      NaN     NaN          NaN   \n",
       "...         ...     ...      ...      ...      ...     ...          ...   \n",
       "228256      NaN     NaN      NaN      NaN      NaN     NaN          NaN   \n",
       "228257      NaN     NaN      NaN      NaN      NaN     NaN          NaN   \n",
       "228258      NaN     NaN      NaN      NaN      NaN     NaN          NaN   \n",
       "228259      NaN     NaN      NaN      NaN      NaN     NaN          NaN   \n",
       "228260      NaN     NaN      NaN      NaN      NaN     NaN          NaN   \n",
       "\n",
       "        USD_RETAIL  USD_UNEMP  \n",
       "0              NaN        NaN  \n",
       "1              NaN        NaN  \n",
       "2              NaN        NaN  \n",
       "3              NaN        NaN  \n",
       "4              NaN        NaN  \n",
       "...            ...        ...  \n",
       "228256         NaN        NaN  \n",
       "228257         NaN        NaN  \n",
       "228258         NaN        NaN  \n",
       "228259         NaN        NaN  \n",
       "228260         NaN        NaN  \n",
       "\n",
       "[228261 rows x 19 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>JPY_CPI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-27 18:30:00</td>\n",
       "      <td>-0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-24 18:30:00</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-03-24 18:30:00</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011-04-27 18:30:00</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011-05-26 18:30:00</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2020-06-25 19:30:00</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2020-07-20 19:30:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2020-08-03 19:30:00</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2020-08-20 19:30:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2020-08-27 19:30:00</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              DATE_TIME  JPY_CPI\n",
       "1   2011-01-27 18:30:00     -0.4\n",
       "3   2011-02-24 18:30:00     -0.2\n",
       "5   2011-03-24 18:30:00     -0.3\n",
       "7   2011-04-27 18:30:00     -0.1\n",
       "9   2011-05-26 18:30:00      0.6\n",
       "..                  ...      ...\n",
       "219 2020-06-25 19:30:00      0.2\n",
       "220 2020-07-20 19:30:00      0.0\n",
       "222 2020-08-03 19:30:00      0.4\n",
       "223 2020-08-20 19:30:00      0.0\n",
       "225 2020-08-27 19:30:00     -0.3\n",
       "\n",
       "[151 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JPY_CPI_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  221  overlapping events\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>EX_DATE_TIME</th>\n",
       "      <th>JPY_GDP</th>\n",
       "      <th>JPY_PPI</th>\n",
       "      <th>JPY_RETAILSALES</th>\n",
       "      <th>JPY_UNEMP</th>\n",
       "      <th>JPY_CPI</th>\n",
       "      <th>JPY_IR</th>\n",
       "      <th>USD_PPI</th>\n",
       "      <th>USD_CPI</th>\n",
       "      <th>USD_GDP</th>\n",
       "      <th>USD_IR</th>\n",
       "      <th>USD_PAYROLL</th>\n",
       "      <th>USD_RETAIL</th>\n",
       "      <th>USD_UNEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-13 08:30:00</td>\n",
       "      <td>82.841</td>\n",
       "      <td>82.728</td>\n",
       "      <td>82.732</td>\n",
       "      <td>82.818</td>\n",
       "      <td>2011-01-13 15:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-24 22:30:00</td>\n",
       "      <td>82.483</td>\n",
       "      <td>82.437</td>\n",
       "      <td>82.483</td>\n",
       "      <td>82.445</td>\n",
       "      <td>2011-01-25 05:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-26 14:15:00</td>\n",
       "      <td>82.425</td>\n",
       "      <td>82.323</td>\n",
       "      <td>82.388</td>\n",
       "      <td>82.326</td>\n",
       "      <td>2011-01-26 21:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-28 08:30:00</td>\n",
       "      <td>82.387</td>\n",
       "      <td>82.298</td>\n",
       "      <td>82.385</td>\n",
       "      <td>82.298</td>\n",
       "      <td>2011-01-28 15:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-15 08:30:00</td>\n",
       "      <td>83.843</td>\n",
       "      <td>83.773</td>\n",
       "      <td>83.781</td>\n",
       "      <td>83.788</td>\n",
       "      <td>2011-02-15 15:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2020-03-12 08:30:00</td>\n",
       "      <td>104.500</td>\n",
       "      <td>104.110</td>\n",
       "      <td>104.136</td>\n",
       "      <td>104.151</td>\n",
       "      <td>2020-03-12 15:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2020-03-15 17:00:00</td>\n",
       "      <td>106.900</td>\n",
       "      <td>106.454</td>\n",
       "      <td>106.846</td>\n",
       "      <td>106.598</td>\n",
       "      <td>2020-03-16 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2020-03-16 01:00:00</td>\n",
       "      <td>106.576</td>\n",
       "      <td>106.328</td>\n",
       "      <td>106.472</td>\n",
       "      <td>106.338</td>\n",
       "      <td>2020-03-16 08:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>2020-03-17 08:30:00</td>\n",
       "      <td>107.139</td>\n",
       "      <td>106.765</td>\n",
       "      <td>106.967</td>\n",
       "      <td>106.802</td>\n",
       "      <td>2020-03-17 15:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>2020-03-18 19:30:00</td>\n",
       "      <td>108.509</td>\n",
       "      <td>108.227</td>\n",
       "      <td>108.238</td>\n",
       "      <td>108.431</td>\n",
       "      <td>2020-03-19 02:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>621 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              DATE_TIME     HIGH      LOW     OPEN    CLOSE  \\\n",
       "0   2011-01-13 08:30:00   82.841   82.728   82.732   82.818   \n",
       "1   2011-01-24 22:30:00   82.483   82.437   82.483   82.445   \n",
       "2   2011-01-26 14:15:00   82.425   82.323   82.388   82.326   \n",
       "3   2011-01-28 08:30:00   82.387   82.298   82.385   82.298   \n",
       "4   2011-02-15 08:30:00   83.843   83.773   83.781   83.788   \n",
       "..                  ...      ...      ...      ...      ...   \n",
       "616 2020-03-12 08:30:00  104.500  104.110  104.136  104.151   \n",
       "617 2020-03-15 17:00:00  106.900  106.454  106.846  106.598   \n",
       "618 2020-03-16 01:00:00  106.576  106.328  106.472  106.338   \n",
       "619 2020-03-17 08:30:00  107.139  106.765  106.967  106.802   \n",
       "620 2020-03-18 19:30:00  108.509  108.227  108.238  108.431   \n",
       "\n",
       "           EX_DATE_TIME  JPY_GDP  JPY_PPI  JPY_RETAILSALES  JPY_UNEMP  \\\n",
       "0   2011-01-13 15:30:00      NaN      NaN              NaN        NaN   \n",
       "1   2011-01-25 05:30:00      NaN      NaN              NaN        NaN   \n",
       "2   2011-01-26 21:15:00      NaN      NaN              NaN        NaN   \n",
       "3   2011-01-28 15:30:00      NaN      NaN              NaN        NaN   \n",
       "4   2011-02-15 15:30:00      NaN      NaN              NaN        NaN   \n",
       "..                  ...      ...      ...              ...        ...   \n",
       "616 2020-03-12 15:30:00      NaN      NaN              NaN        NaN   \n",
       "617 2020-03-16 00:00:00      NaN      NaN              NaN        NaN   \n",
       "618 2020-03-16 08:00:00      NaN      NaN              NaN        NaN   \n",
       "619 2020-03-17 15:30:00      NaN      NaN              NaN        NaN   \n",
       "620 2020-03-19 02:30:00      NaN      NaN              NaN        NaN   \n",
       "\n",
       "     JPY_CPI  JPY_IR  USD_PPI  USD_CPI  USD_GDP  USD_IR  USD_PAYROLL  \\\n",
       "0        NaN     NaN      1.1      NaN      NaN     NaN          NaN   \n",
       "1        NaN     0.1      NaN      NaN      NaN     NaN          NaN   \n",
       "2        NaN     NaN      NaN      NaN      NaN    0.25          NaN   \n",
       "3        NaN     NaN      NaN      NaN      3.2     NaN          NaN   \n",
       "4        NaN     NaN      NaN      NaN      NaN     NaN          NaN   \n",
       "..       ...     ...      ...      ...      ...     ...          ...   \n",
       "616      NaN     NaN     -0.6      NaN      NaN     NaN          NaN   \n",
       "617      NaN     NaN      NaN      NaN      NaN    0.25          NaN   \n",
       "618      NaN    -0.1      NaN      NaN      NaN     NaN          NaN   \n",
       "619      NaN     NaN      NaN      NaN      NaN     NaN          NaN   \n",
       "620      0.6     NaN      NaN      NaN      NaN     NaN          NaN   \n",
       "\n",
       "     USD_RETAIL  USD_UNEMP  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           0.3        NaN  \n",
       "..          ...        ...  \n",
       "616         NaN        NaN  \n",
       "617         NaN        NaN  \n",
       "618         NaN        NaN  \n",
       "619        -0.5        NaN  \n",
       "620         NaN        NaN  \n",
       "\n",
       "[621 rows x 19 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking whether is there any overlapping events in the merged dataframe\n",
    "\n",
    "\n",
    "temp_df = new_df.drop(columns = ['DATE_TIME','HIGH','LOW','OPEN','CLOSE','EX_DATE_TIME']).notnull().sum(axis=1) # A Series of counting number of non 'nan' values accross a row\n",
    "\n",
    "#A function to checking number of overlap events\n",
    "\n",
    "def OverlapCounter(t_df):\n",
    "    count = 0\n",
    "    for i in t_df:\n",
    "        if i>1:\n",
    "            count+=1\n",
    "    print('There are ', count, ' overlapping events')\n",
    "    \n",
    "\n",
    "OverlapCounter(temp_df)# count overlap events\n",
    "\n",
    "t_df = new_df[temp_df==1] #avoid overlapping non event columns\n",
    "df_with_reset_index = t_df.reset_index(drop=True)\n",
    "df_with_reset_index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 621 entries, 0 to 620\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   DATE_TIME    621 non-null    datetime64[ns]\n",
      " 1   HIGH         621 non-null    float64       \n",
      " 2   LOW          621 non-null    float64       \n",
      " 3   OPEN         621 non-null    float64       \n",
      " 4   CLOSE        621 non-null    float64       \n",
      " 5   Event_value  621 non-null    float64       \n",
      " 6   Event_type   621 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(5), object(1)\n",
      "memory usage: 34.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['USD_PPI', 'JPY_IR', 'USD_IR', 'USD_GDP', 'USD_RETAIL', 'USD_CPI',\n",
       "       'JPY_CPI', 'JPY_UNEMP'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x= df_with_reset_index.drop(columns = ['DATE_TIME','HIGH','LOW','OPEN','CLOSE','EX_DATE_TIME'])\n",
    "\n",
    "event_type = []\n",
    "event_values=[]\n",
    "for i in range(len(x)):\n",
    "    for col in x.columns:\n",
    "        val = x.loc[i,col]\n",
    "        if str(val) != 'nan':\n",
    "            event_type.append(col)\n",
    "            \n",
    "            event_values.append(val)\n",
    "            \n",
    "df_with_reset_index['Event_value'] = event_values\n",
    "df_with_reset_index['Event_type'] = event_type \n",
    "\n",
    "# rearrange the data frame by keeping only desired columns\n",
    "train_df = df_with_reset_index[['DATE_TIME','HIGH', 'LOW','OPEN','CLOSE', 'Event_value','Event_type']]\n",
    "\n",
    "\n",
    "train_df['HIGH'] = pd.to_numeric(train_df['HIGH'])\n",
    "train_df['LOW'] = pd.to_numeric(train_df['LOW'])\n",
    "train_df['OPEN'] = pd.to_numeric(train_df['OPEN'])\n",
    "train_df['CLOSE'] = pd.to_numeric(train_df['CLOSE'])\n",
    "train_df.info()\n",
    "train_df['Event_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    \n",
    "    tempor_df = pd.DataFrame({}) # created a temporary dataframe in order to store shifting dates\n",
    "\n",
    "    tempor_df['DATE_TIME'] = train_df['DATE_TIME'] + pd.Timedelta(minutes=15*(i+1)) #shift the time by 15 minutes of slicers  \n",
    "\n",
    "    x = pd.merge(df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE']],tempor_df, how='right', on='DATE_TIME') # merge the shifted date column and join HIGH, LOW values in the pip data set \n",
    "    \n",
    "    x_1 = x['HIGH'].fillna(method = 'bfill') # filling 'nan' values with the next value respected to the 'nan'\n",
    "    x_2 = x['LOW'].fillna(method= 'bfill')\n",
    "    x_3 = x['CLOSE'].fillna(method = 'bfill')\n",
    "    x_4 = x['OPEN'].fillna(method = 'bfill')\n",
    "    \n",
    "    col_name = 'after_'+ str(15*(i+1)) + '_mins'#column names that included (open+close)/2 values 0-120 min in time duration\n",
    "\n",
    "    train_df[col_name] = (x_1 + x_2 + x_3 + x_4)/4\n",
    "       \n",
    "my_df = pd.DataFrame({})\n",
    " \n",
    "init_value = (train_df.iloc[:,1] + train_df.iloc[:,2] + train_df.iloc[:,3] +train_df.iloc[:,4])/4\n",
    "\n",
    "for i in range(8):\n",
    "    col = 'defference of avg from_' + str((i)*15) +'_to_' + str((i+1)*15) \n",
    "     \n",
    "     \n",
    "    my_df[col] = abs(train_df.iloc[:,i+7] - init_value)\n",
    "     \n",
    "    init_value = train_df.iloc[:,i+7]\n",
    "     \n",
    "\n",
    "\n",
    " \n",
    " \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE','Event_value','Event_type']]\n",
    "\n",
    "col = my_df.columns\n",
    "new_s = my_df[col].apply(lambda row: ' '.join(row.values.astype(str)), axis=1) # combine all the values in a row in the train_df into a one string\n",
    "\n",
    "def timeDuration(x):\n",
    "    a = x.split()\n",
    "    l = list(map(float,a))\n",
    "    y = ((l[0]+l[1])/2)*0.75\n",
    "    l.pop(0)\n",
    "    l.pop(0)\n",
    "    l = [x for x in l if x>=y ] \n",
    "    if len(l) >=3:\n",
    "        p = 'Long term'\n",
    "    else:\n",
    "        p= 'Short term'\n",
    "        \n",
    "    return p\n",
    "    \n",
    "train_df['Time duration'] = new_s.apply(lambda x: timeDuration(x))  \n",
    "   \n",
    "   \n",
    "    \n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the trend when an event happen\n",
    "def trend(x):\n",
    "    \n",
    "    if x == datetime.datetime(2020,3,18,20,30,0):\n",
    "        final = 0\n",
    "    else:\n",
    "        initial_value  =  x - datetime.timedelta(hours= 25)\n",
    "    \n",
    "    \n",
    "        init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "    \n",
    "    \n",
    "        forward_factor = 0\n",
    "        backward_factor = 0\n",
    "    \n",
    "        while len(init_check) != 1:\n",
    "            delta_time = datetime.timedelta(minutes=15)\n",
    "            initial_value = initial_value + delta_time\n",
    "            init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "            forward_factor+= 1\n",
    "     \n",
    "    \n",
    "        initial_value  =  x - datetime.timedelta(hours= 25)\n",
    "        init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "        while len(init_check) !=1:\n",
    "            delta_time = datetime.timedelta(minutes=15)\n",
    "            initial_value = initial_value - delta_time\n",
    "            init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "            backward_factor +=1\n",
    "     \n",
    "     \n",
    "        net_factor = backward_factor + forward_factor \n",
    "        initial_value = initial_value - datetime.timedelta(minutes=15)*(net_factor)\n",
    "     \n",
    "        max_= 0\n",
    "        min_ = 1000\n",
    "        val= 0\n",
    "        for i in range(99):\n",
    "            time_delta = datetime.timedelta(minutes=15*(99-i))\n",
    "            date = x - time_delta\n",
    "            s = df[df['DATE_TIME']== date]['OPEN']\n",
    "         \n",
    "            if len(s)==1:\n",
    "                date = date\n",
    "        \n",
    "            else:\n",
    "                time_shift = datetime.timedelta(minutes=15)* (net_factor)\n",
    "                date = date - time_shift\n",
    "        \n",
    "        \n",
    "            avg_1 =(df[df['DATE_TIME'] == date ]['OPEN'] + df[df['DATE_TIME']==date ]['CLOSE'])/2   \n",
    "            avg_2 = (df[df['DATE_TIME'] == initial_value ]['OPEN'] + df[df['DATE_TIME']== initial_value ]['CLOSE'])/2     \n",
    "        \n",
    "       \n",
    "        \n",
    "            if len(avg_1) !=1  or len(avg_2) !=1:\n",
    "                val = val\n",
    "        \n",
    "            else:\n",
    "                val = abs(float(avg_1) - float(avg_2))\n",
    "         \n",
    "             \n",
    "        \n",
    "        \n",
    "            if val> max_:\n",
    "                max_=val\n",
    "            else:\n",
    "                max_ = max_\n",
    "            \n",
    "            if val < min_:\n",
    "                min_ = val\n",
    "            else:\n",
    "                min_ = min_\n",
    "        \n",
    "            initial_value = date\n",
    "     \n",
    " \n",
    "     \n",
    "  \n",
    "\n",
    "        initial_value  =  x + datetime.timedelta(hours= 25)\n",
    "    \n",
    "     \n",
    "        init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "    \n",
    "        forward_factor = 0\n",
    "        backward_factor = 0\n",
    "    \n",
    "        while len(init_check) != 1:\n",
    "            delta_time = datetime.timedelta(minutes=15)\n",
    "            initial_value = initial_value + delta_time\n",
    "            init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "            forward_factor+= 1\n",
    "        \n",
    "     \n",
    "    \n",
    "        initial_value  =  x + datetime.timedelta(hours= 25)\n",
    "        init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "    \n",
    "        while len(init_check) !=1:\n",
    "            delta_time = datetime.timedelta(minutes=15)\n",
    "            initial_value = initial_value - delta_time\n",
    "            init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "            backward_factor +=1\n",
    "        \n",
    "     \n",
    "     \n",
    "        net_factor = backward_factor + forward_factor\n",
    "        initial_value  =  x + datetime.timedelta(hours= 25) \n",
    "        initial_value = initial_value + datetime.timedelta(minutes=15)*(net_factor)\n",
    "        val=0\n",
    "        for i in range(100):\n",
    "            time_delta = datetime.timedelta(minutes=15*(99-i))\n",
    "            date = x + time_delta\n",
    "            s = df[df['DATE_TIME']== date]['OPEN']\n",
    "        \n",
    "            if len(s)==1:\n",
    "                date = date\n",
    "        \n",
    "            else:\n",
    "                time_shift = datetime.timedelta(minutes=15)* (net_factor)\n",
    "                date = date + time_shift\n",
    "            \n",
    "                \n",
    "            avg_1 =(df[df['DATE_TIME'] == date ]['OPEN'] + df[df['DATE_TIME']==date ]['CLOSE'])/2   \n",
    "            avg_2 = (df[df['DATE_TIME'] == initial_value ]['OPEN'] + df[df['DATE_TIME']== initial_value ]['CLOSE'])/2     \n",
    "         \n",
    "            if len(avg_1) !=1  or len(avg_2) !=1 :\n",
    "                val = val\n",
    "            else:\n",
    "                 val = abs(float(avg_1) - float(avg_2))\n",
    "         \n",
    "            if val> max_:\n",
    "                max_=val\n",
    "            else:\n",
    "                max_ = max_\n",
    "            \n",
    "            if val < min_:\n",
    "                min_ = val\n",
    "            else:\n",
    "                min_ = min_\n",
    "        \n",
    "            initial_value = date\n",
    "        final = min_ + (max_ - min_)*0.10 \n",
    "        \n",
    "    return final   \n",
    "           \n",
    "    \n",
    "         \n",
    "trend(train_df['DATE_TIME'][25] )\n",
    "train_df = train_df.iloc[:620,:]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df['Boundaries'] = train_df['DATE_TIME'].apply(lambda x : trend(x))\n",
    "for i in range(2):\n",
    "    \n",
    "    tempor_df = pd.DataFrame({}) # created a temporary dataframe in order to store shifting dates\n",
    "    \n",
    "    tempor_df['DATE_TIME'] = train_df['DATE_TIME'] - pd.Timedelta(minutes=15*(2-i)) #shift the time by 15 minutes of slicers  \n",
    "\n",
    "    x = pd.merge(df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE']],tempor_df, how='right', on='DATE_TIME') # merge the shifted date column and join HIGH, LOW values in the pip data set \n",
    "\n",
    "    \n",
    "    x_1 = x['CLOSE'].fillna(method = 'bfill')\n",
    "    x_2 = x['OPEN'].fillna(method = 'bfill')\n",
    "    \n",
    "    col_name = '_before'+ str(15*(2-i)) + '_mins' + '_in_trend'#column names that included (open+close)/2 values 0-120 min in time duration\n",
    "\n",
    "    train_df[col_name] = (x_1 + x_2 )/2\n",
    "    \n",
    "for i in range(8):\n",
    "    \n",
    "    tempor_df = pd.DataFrame({}) # created a temporary dataframe in order to store shifting dates\n",
    "\n",
    "    tempor_df['DATE_TIME'] = train_df['DATE_TIME'] + pd.Timedelta(minutes=15*(1+i)) #shift the time by 15 minutes of slicers  \n",
    "\n",
    "    x = pd.merge(df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE']],tempor_df, how='right', on='DATE_TIME') # merge the shifted date column and join HIGH, LOW values in the pip data set \n",
    "\n",
    "    \n",
    "    x_1 = x['CLOSE'].fillna(method = 'bfill')\n",
    "    x_2 = x['OPEN'].fillna(method = 'bfill')\n",
    "    \n",
    "    col_name = '_after'+ str(15*(1+i)) + '_mins' + '_in_trend'#column names that included (open+close)/2 values 0-120 min in time duration\n",
    "\n",
    "    train_df[col_name] = (x_1 + x_2 )/2\n",
    "    \n",
    "train_df\n",
    "my_df = pd.DataFrame({})\n",
    " \n",
    "init_value = (train_df.iloc[:,3] +train_df.iloc[:,4])/2\n",
    "\n",
    "for i in range(8):\n",
    "    col = 'defference of avg in ' +  'slot ' + str(i+1) + ' in trend'\n",
    "     \n",
    "     \n",
    "    my_df[col] = train_df.iloc[:,i+9] - init_value\n",
    "     \n",
    "    init_value = train_df.iloc[:,i+9]  \n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df\n",
    "trend = []\n",
    "\n",
    "def final_trend(x):\n",
    "    return {up_count: 'UP' ,down_count: 'DOWN', range_count: 'RANGE'}.get(x)\n",
    "\n",
    "for i in range(len(my_df)):\n",
    "    up_count = 0\n",
    "    down_count = 0\n",
    "    range_count = 0\n",
    "    for col in my_df.columns :\n",
    "        val = my_df.loc[i,col]\n",
    "        lower_boundary = (-1)*(train_df['Boundaries'][i])\n",
    "        upper_boundary = train_df['Boundaries'][i]\n",
    "        if val > upper_boundary:\n",
    "            up_count+=1\n",
    "        elif val< lower_boundary :\n",
    "            down_count+=1\n",
    "        else:\n",
    "            range_count+=1\n",
    "    x = max(up_count,down_count,range_count)\n",
    "    trend.append(final_trend(x))\n",
    "                 \n",
    "train_df['Trend'] = trend\n",
    "     \n",
    "train_df= train_df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE','Event_value','Event_type','Time duration','Trend','Boundaries']]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "x= train_df[train_df['Trend']== 'RANGE'].reset_index(drop=True)\n",
    "x['val']=0\n",
    "\n",
    "for i in range(11):\n",
    "    t= pd.DataFrame({})\n",
    "    t['DATE_TIME']= x['DATE_TIME']+pd.Timedelta(minutes = (-45) + (i+1)*15 )\n",
    "    j= pd.merge(df[['DATE_TIME','HIGH','LOW']],t, how='right', on='DATE_TIME')\n",
    "    x_1 = j['HIGH'].fillna(method = 'bfill')\n",
    "    x_2 = j['LOW'].fillna(method = 'bfill')\n",
    "    \n",
    "    val = (x_1 - x_2)/11\n",
    "    x['val'] = x['val'] + val\n",
    "\n",
    "range_dict = dict(x.groupby('Event_type').val.mean())\n",
    "print(range_dict)\n",
    "count = 0\n",
    "for i in range_dict.values():\n",
    "    range_dict[list(range_dict.keys())[count]] = i/2\n",
    "    count+=1\n",
    "range_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= train_df[train_df['Trend']== 'UP'].reset_index(drop=True)\n",
    "y['open_close_avg'] = 0\n",
    "y['high_avg'] = 0\n",
    "for i in range(11):\n",
    "    t= pd.DataFrame({})\n",
    "    t['DATE_TIME']= y['DATE_TIME'] + pd.Timedelta(minutes = (-45) + (i+1)*15 )\n",
    "    k= pd.merge(df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE']],t, how='right', on='DATE_TIME')\n",
    "    y_1 = k['CLOSE'].fillna(method = 'bfill')\n",
    "    y_2 = k['OPEN'].fillna(method = 'bfill')\n",
    "    y_3 = k['HIGH'].fillna(method = 'bfill')\n",
    "    \n",
    "    open_close_avg = (y_1 + y_2)/2\n",
    "    y['high_avg'] = y['high_avg'] +  y_3\n",
    "    y['open_close_avg'] = y['open_close_avg'] + open_close_avg\n",
    "    \n",
    "y['strength'] = (y['high_avg'])/11 - (y['open_close_avg'])/11\n",
    "y= y.set_index('DATE_TIME')\n",
    "    \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z= train_df[train_df['Trend']== 'DOWN'].reset_index(drop=True)\n",
    "z['open_close_avg'] = 0\n",
    "z['low_avg'] = 0\n",
    "for i in range(11):\n",
    "    t= pd.DataFrame({})\n",
    "    t['DATE_TIME']= z['DATE_TIME'] + pd.Timedelta(minutes = (-45) + (i+1)*15 )\n",
    "    l= pd.merge(df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE']],t, how='right', on='DATE_TIME')\n",
    "    z_1 = l['CLOSE'].fillna(method = 'bfill')\n",
    "    z_2 = l['OPEN'].fillna(method = 'bfill')\n",
    "    z_3 = l['LOW'].fillna(method = 'bfill')\n",
    "    \n",
    "    open_close_avg = (z_1 + z_2)/2\n",
    "    z['low_avg'] = z['low_avg'] +  z_3\n",
    "    z['open_close_avg'] = z['open_close_avg'] + open_close_avg\n",
    "    \n",
    "z['strength'] = (z['low_avg'])/11 - (z['open_close_avg'])/11\n",
    "z= z.set_index('DATE_TIME') \n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength = []\n",
    "\n",
    "for i in range(len(train_df)):\n",
    "    if train_df['Trend'][i] == 'DOWN' :\n",
    "        strength.append(z['strength'][train_df['DATE_TIME'][i]])\n",
    "    elif train_df['Trend'][i] == 'UP' :\n",
    "        strength.append(y['strength'][train_df['DATE_TIME'][i]])\n",
    "     \n",
    "    else :\n",
    "        strength.append(range_dict[train_df['Event_type'][i]])\n",
    "train_df['strength'] = strength\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['time'] = train_df['DATE_TIME'].dt.time \n",
    "train_df['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('JPY-USD train set.csv', encoding = \"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

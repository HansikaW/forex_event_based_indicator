{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>USD_RETAIL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-14 08:30:00</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-02-01 04:00:00</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-15 08:30:00</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-03-01 04:00:00</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2020-04-15 08:30:00</td>\n",
       "      <td>-8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2020-05-15 08:30:00</td>\n",
       "      <td>-16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2020-06-16 08:30:00</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2020-07-16 08:30:00</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2020-08-14 08:30:00</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              DATE_TIME  USD_RETAIL\n",
       "0   2011-01-01 04:00:00         0.1\n",
       "1   2011-01-14 08:30:00         0.6\n",
       "2   2011-02-01 04:00:00         0.8\n",
       "3   2011-02-15 08:30:00         0.3\n",
       "4   2011-03-01 04:00:00         0.4\n",
       "..                  ...         ...\n",
       "157 2020-04-15 08:30:00        -8.7\n",
       "158 2020-05-15 08:30:00       -16.4\n",
       "159 2020-06-16 08:30:00        17.7\n",
       "160 2020-07-16 08:30:00         7.5\n",
       "161 2020-08-14 08:30:00         1.2\n",
       "\n",
       "[162 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPORT ALL THE FILES AND KEEP ONLY DESIRERED COLUMNS OF THE EVENT DATA\n",
    "\n",
    "col = ['DATE','TIME','c','D','E','F','G','AUD_GDP','I','J']\n",
    "drop_cols = ['c','D','E','F','G','I','J']\n",
    "\n",
    "AUD_USD_df = pd.read_csv('AUDUSD-2000-2020-15m.csv') #AUS_USD CURRENCY DATA SET\n",
    "\n",
    "# import all the event files, variable name tells what is the event\n",
    "#use 'parse_dates' keyword ynside the 'read_csv' function in order to combine date and time also convert the data type into 'datetime64'\n",
    "AUD_GDP_df = pd.read_csv('AUD_GDP.csv',header = None,names =['DATE','TIME','c','D','E','F','G','AUD_GDP','I','J'] ,parse_dates= [[0,1]]) \n",
    "AUD_GDP_df = AUD_GDP_df.drop(columns=drop_cols)\n",
    "\n",
    "AUD_PPI_df = pd.read_csv('AUD_PPI.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','AUD_PPI','I','J'],parse_dates= [[0,1]])\n",
    "AUD_PPI_df = AUD_PPI_df.drop(columns=drop_cols)\n",
    "\n",
    "AUD_RETAILSALES_df = pd.read_csv('AUD_RETAILSALES.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','AUD_RETAILSALES','I','J'],parse_dates= [[0,1]])\n",
    "AUD_RETAILSALES_df = AUD_RETAILSALES_df.drop(columns=drop_cols)\n",
    "\n",
    "AUD_UNEMP_df = pd.read_csv('AUD_UNEMP.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','AUD_UNEMP','I','J'],parse_dates= [[0,1]])\n",
    "AUD_UNEMP_df = AUD_UNEMP_df.drop(columns=drop_cols)\n",
    "\n",
    "AUD_CPI_df = pd.read_csv('AUD_CPI.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','AUD_CPI','I','J'],parse_dates= [[0,1]])\n",
    "AUD_CPI_df = AUD_CPI_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_CPI_df = pd.read_csv('USD_CPI.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_CPI','I','J'],parse_dates= [[0,1]])\n",
    "USD_CPI_df = USD_CPI_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_GDP_df = pd.read_csv('USD_GDP.csv',header = None,names =['DATE','TIME','c','D','E','F','G','USD_GDP','I','J'],parse_dates= [[0,1]])\n",
    "USD_GDP_df = USD_GDP_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_IR_df = pd.read_csv('USD_IR.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_IR','I','J'],parse_dates= [[0,1]])\n",
    "USD_IR_df = USD_IR_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_PAYROLL_df = pd.read_csv('USD_PAYROLL.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_PAYROLL','I','J'],parse_dates= [[0,1]])\n",
    "USD_PAYROLL_df = USD_PAYROLL_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_PPI_df = pd.read_csv('USD_PPI.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_PPI','I','J'],parse_dates= [[0,1]])\n",
    "USD_PPI_df = USD_PPI_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_RETAIL_df = pd.read_csv('USD_RETAIL.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_RETAIL','I','J'],parse_dates= [[0,1]])\n",
    "USD_RETAIL_df = USD_RETAIL_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_UNEMP_df = pd.read_csv('USD_UNEMP.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_UNEMP','I','J'],parse_dates= [[0,1]])\n",
    "USD_UNEMP_df = USD_UNEMP_df.drop(columns=drop_cols)\n",
    "\n",
    "\n",
    "USD_RETAIL_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  187  overlapping events\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>CLOSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-02 17:00:00</td>\n",
       "      <td>1.02229</td>\n",
       "      <td>1.02119</td>\n",
       "      <td>1.02218</td>\n",
       "      <td>1.02138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-02 17:15:00</td>\n",
       "      <td>1.02132</td>\n",
       "      <td>1.02041</td>\n",
       "      <td>1.02131</td>\n",
       "      <td>1.02049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-02 17:30:00</td>\n",
       "      <td>1.02144</td>\n",
       "      <td>1.02023</td>\n",
       "      <td>1.02049</td>\n",
       "      <td>1.02125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-02 17:45:00</td>\n",
       "      <td>1.02149</td>\n",
       "      <td>1.02116</td>\n",
       "      <td>1.02129</td>\n",
       "      <td>1.02117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-02 18:00:00</td>\n",
       "      <td>1.02214</td>\n",
       "      <td>1.02084</td>\n",
       "      <td>1.02118</td>\n",
       "      <td>1.02099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227880</th>\n",
       "      <td>2020-03-18 22:00:00</td>\n",
       "      <td>0.55519</td>\n",
       "      <td>0.55138</td>\n",
       "      <td>0.55518</td>\n",
       "      <td>0.55405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227881</th>\n",
       "      <td>2020-03-18 22:15:00</td>\n",
       "      <td>0.55528</td>\n",
       "      <td>0.55269</td>\n",
       "      <td>0.55406</td>\n",
       "      <td>0.55427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227882</th>\n",
       "      <td>2020-03-18 22:30:00</td>\n",
       "      <td>0.56336</td>\n",
       "      <td>0.55408</td>\n",
       "      <td>0.55427</td>\n",
       "      <td>0.55843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227883</th>\n",
       "      <td>2020-03-18 22:45:00</td>\n",
       "      <td>0.55907</td>\n",
       "      <td>0.55530</td>\n",
       "      <td>0.55846</td>\n",
       "      <td>0.55576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227884</th>\n",
       "      <td>2020-03-18 23:00:00</td>\n",
       "      <td>0.55812</td>\n",
       "      <td>0.55576</td>\n",
       "      <td>0.55576</td>\n",
       "      <td>0.55712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227885 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATE_TIME     HIGH      LOW     OPEN    CLOSE\n",
       "0      2011-01-02 17:00:00  1.02229  1.02119  1.02218  1.02138\n",
       "1      2011-01-02 17:15:00  1.02132  1.02041  1.02131  1.02049\n",
       "2      2011-01-02 17:30:00  1.02144  1.02023  1.02049  1.02125\n",
       "3      2011-01-02 17:45:00  1.02149  1.02116  1.02129  1.02117\n",
       "4      2011-01-02 18:00:00  1.02214  1.02084  1.02118  1.02099\n",
       "...                    ...      ...      ...      ...      ...\n",
       "227880 2020-03-18 22:00:00  0.55519  0.55138  0.55518  0.55405\n",
       "227881 2020-03-18 22:15:00  0.55528  0.55269  0.55406  0.55427\n",
       "227882 2020-03-18 22:30:00  0.56336  0.55408  0.55427  0.55843\n",
       "227883 2020-03-18 22:45:00  0.55907  0.55530  0.55846  0.55576\n",
       "227884 2020-03-18 23:00:00  0.55812  0.55576  0.55576  0.55712\n",
       "\n",
       "[227885 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select the data from 2011-2020 from the 'AUD_USD_df' data set where the pips are located.\n",
    "\n",
    "d =AUD_USD_df.loc[272142:500027 ,:]\n",
    "df = d.reset_index(drop=True)\n",
    "df['DATE_TIME'] = pd.to_datetime(df['DATE_TIME'])\n",
    "df['DATE_TIME'] = df['DATE_TIME']-pd.Timedelta(hours=7)\n",
    "\n",
    "pd.options.mode.chained_assignment = None  #  not important codeline. This is for avoiding the warning of chained assignments\n",
    "\n",
    "\n",
    "#merge all the dataframes (all the events of both countries and market prices by matching with the date and time values)\n",
    "\n",
    "new_df =  df.merge(AUD_GDP_df, on = 'DATE_TIME', how = 'left')\\\n",
    "          .merge(AUD_PPI_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(AUD_RETAILSALES_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(AUD_UNEMP_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(AUD_CPI_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_PPI_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_CPI_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_GDP_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_IR_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_PAYROLL_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_RETAIL_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_UNEMP_df, on = 'DATE_TIME', how = 'left')\n",
    "            \n",
    "#checking whether is there any overlapping events in the merged dataframe\n",
    "\n",
    "temp_df = new_df.drop(columns = ['DATE_TIME','HIGH','LOW','OPEN','CLOSE']).notnull().sum(axis=1) # A Series of counting number of non 'nan' values accross a row\n",
    "\n",
    "#A function to checking number of overlap events\n",
    "\n",
    "def OverlapCounter(t_df):\n",
    "    count = 0\n",
    "    for i in t_df:\n",
    "        if i>1:\n",
    "            count+=1\n",
    "    print('There are ', count, ' overlapping events')\n",
    "    \n",
    "\n",
    "print(OverlapCounter(temp_df)) # count overlap events\n",
    "\n",
    "t_df = new_df[temp_df==1]   #filter and make a new datframe that combining all the non overlapping events\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (2295) does not match length of index (765)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-b15271d7c567>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mevent_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdf_with_reset_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Event_value'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevent_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mdf_with_reset_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Event_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3039\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3040\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3114\u001b[0m         \"\"\"\n\u001b[0;32m   3115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3116\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3117\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3762\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3763\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3765\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m         raise ValueError(\n\u001b[1;32m--> 748\u001b[1;33m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[1;34m\"does not match length of index \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (2295) does not match length of index (765)"
     ]
    }
   ],
   "source": [
    "# create two new columns. One column including the type of the event while the other consisiting with the relevant event value\n",
    "\n",
    "x= df_with_reset_index.drop(columns = ['DATE_TIME','HIGH','LOW','OPEN','CLOSE'])\n",
    "\n",
    "event_type = []\n",
    "event_values=[]\n",
    "for i in range(len(x)):\n",
    "    for col in x.columns:\n",
    "        val = x.loc[i,col]\n",
    "        if str(val) != 'nan':\n",
    "            event_type.append(col)\n",
    "            \n",
    "            event_values.append(val)\n",
    "            \n",
    "df_with_reset_index['Event_value'] = event_values\n",
    "df_with_reset_index['Event_type'] = event_type\n",
    "        \n",
    "df_with_reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange the data frame by keeping only desired columns\n",
    "train_df = df_with_reset_index[['DATE_TIME','HIGH', 'LOW','OPEN','CLOSE','Event_value','Event_type']]\n",
    "\n",
    "\n",
    "\n",
    "AUD_USD_df['DATE_TIME'] = pd.to_datetime(AUD_USD_df['DATE_TIME']) #convert to datetime object\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "    \n",
    "    tempor_df = pd.DataFrame({}) # created a temporary dataframe in order to store shifting dates\n",
    "\n",
    "    tempor_df['DATE_TIME'] = train_df['DATE_TIME'] + pd.Timedelta(minutes=15*(i+1)) #shift the time by 15 minutes of slicers  \n",
    "\n",
    "    x = pd.merge(AUD_USD_df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE']],tempor_df, how='right', on='DATE_TIME') # merge the shifted date column and join HIGH, LOW values in the pip data set \n",
    "\n",
    "    x_1 = x['HIGH'].fillna(method = 'bfill') # missing 'nan' values with the next value respected to the 'nan'\n",
    "    x_2 = x['LOW'].fillna(method= 'bfill')\n",
    "    x_3 = x['CLOSE'].fillna(method = 'bfill')\n",
    "    x_4 = x['OPEN'].fillna(method = 'bfill')\n",
    "    \n",
    "    col_name = 'average_value_after_'+ str(15*(i+1)) + '_mins'\n",
    "    \n",
    "    train_df[col_name] = (x_1 + x_2 + x_3 + x_4)/4\n",
    "\n",
    "    \n",
    "my_df = pd.DataFrame({}) \n",
    "init_value = (train_df.iloc[:,1] + train_df.iloc[:,2] + train_df.iloc[:,3] +train_df.iloc[:,4])/4\n",
    "for i in range(7):\n",
    "    col = 'defference of avg from_' + str((i)*15) +'_to_' + str((i+1)*15) \n",
    "    my_df[col] = train_df.iloc[:,i+7] - init_value\n",
    "    init_value = train_df.iloc[:,i+7]\n",
    "    \n",
    "my_df\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE','Event_value','Event_type']].join(my_df)\n",
    "\n",
    "col = my_df.columns\n",
    "new_s = my_df[col].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "list_1 = (new_s[0]).split()\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

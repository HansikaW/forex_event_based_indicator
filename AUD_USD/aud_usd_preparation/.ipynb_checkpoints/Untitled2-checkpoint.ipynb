{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#IMPORT ALL THE FILES AND KEEP ONLY DESIRERED COLUMNS OF THE EVENT DATA\n",
    "\n",
    "pd.options.mode.chained_assignment = None  #  no important. This is for avoiding the warning of chained assignments\n",
    "\n",
    "drop_cols = ['c','D','E','F','G','I','J'] \n",
    "\n",
    "AUD_USD_df = pd.read_csv('AUDUSD-2000-2020-15m.csv') #AUS_USD CURRENCY DATA SET\n",
    "\n",
    "# import all the event files, variable name tells what is the event\n",
    "#use 'parse_dates' keyword ynside the 'read_csv' function in order to combine date and time also convert the data type into 'datetime64'\n",
    "AUD_GDP_df = pd.read_csv('AUD_GDP.csv',header = None,names =['DATE','TIME','c','D','E','F','G','AUD_GDP','I','J'] ,parse_dates= [[0,1]]) \n",
    "AUD_GDP_df = AUD_GDP_df.drop(columns=drop_cols)\n",
    "\n",
    "\n",
    "AUD_PPI_df = pd.read_csv('AUD_PPI.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','AUD_PPI','I','J'],parse_dates= [[0,1]])\n",
    "AUD_PPI_df = AUD_PPI_df.drop(columns=drop_cols)\n",
    "\n",
    "AUD_RETAILSALES_df = pd.read_csv('AUD_RETAILSALES.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','AUD_RETAILSALES','I','J'],parse_dates= [[0,1]])\n",
    "AUD_RETAILSALES_df = AUD_RETAILSALES_df.drop(columns=drop_cols)\n",
    "\n",
    "AUD_UNEMP_df = pd.read_csv('AUD_UNEMP.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','AUD_UNEMP','I','J'],parse_dates= [[0,1]])\n",
    "AUD_UNEMP_df = AUD_UNEMP_df.drop(columns=drop_cols)\n",
    "\n",
    "AUD_CPI_df = pd.read_csv('AUD_CPI.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','AUD_CPI','I','J'],parse_dates= [[0,1]])\n",
    "AUD_CPI_df = AUD_CPI_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_CPI_df = pd.read_csv('USD_CPI.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_CPI','I','J'],parse_dates= [[0,1]])\n",
    "USD_CPI_df = USD_CPI_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_GDP_df = pd.read_csv('USD_GDP.csv',header = None,names =['DATE','TIME','c','D','E','F','G','USD_GDP','I','J'],parse_dates= [[0,1]])\n",
    "USD_GDP_df = USD_GDP_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_IR_df = pd.read_csv('USD_IR.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_IR','I','J'],parse_dates= [[0,1]])\n",
    "USD_IR_df = USD_IR_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_PAYROLL_df = pd.read_csv('USD_PAYROLL.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_PAYROLL','I','J'],parse_dates= [[0,1]])\n",
    "USD_PAYROLL_df = USD_PAYROLL_df.drop(columns=drop_cols)\n",
    "USD_PAYROLL_df['USD_PAYROLL'] = (USD_PAYROLL_df['USD_PAYROLL'])/1000 \n",
    "\n",
    "\n",
    "USD_PPI_df = pd.read_csv('USD_PPI.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_PPI','I','J'],parse_dates= [[0,1]])\n",
    "USD_PPI_df = USD_PPI_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_RETAIL_df = pd.read_csv('USD_RETAIL.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_RETAIL','I','J'],parse_dates= [[0,1]])\n",
    "USD_RETAIL_df = USD_RETAIL_df.drop(columns=drop_cols)\n",
    "\n",
    "USD_UNEMP_df = pd.read_csv('USD_UNEMP.csv',header = None,names = ['DATE','TIME','c','D','E','F','G','USD_UNEMP','I','J'],parse_dates= [[0,1]])\n",
    "USD_UNEMP_df = USD_UNEMP_df.drop(columns=drop_cols)\n",
    "\n",
    "\n",
    "USD_PAYROLL_df['USD_PAYROLL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#select the data from 2011-2020 from the 'AUD_USD_df' data set where the pips are located.\n",
    "\n",
    "d =AUD_USD_df.loc[272142:500027 ,:]\n",
    "df = d.reset_index(drop=True)\n",
    "df['EX_DATE_TIME'] = pd.to_datetime(df['DATE_TIME']) # convert the type to datetime\n",
    "df['DATE_TIME'] = df['EX_DATE_TIME']- pd.Timedelta(hours=7)\n",
    " # substract 7 hours from the currency set\n",
    "\n",
    "#merge all the dataframes (all the events of both countries and market prices by matching with the date and time values)\n",
    " \n",
    "            \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#merging the events details and pips details according to date\n",
    "new_df =  df.merge(AUD_GDP_df, on = 'DATE_TIME', how = 'left')\\\n",
    "          .merge(AUD_PPI_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(AUD_RETAILSALES_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(AUD_UNEMP_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(AUD_CPI_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_PPI_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_CPI_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_GDP_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_IR_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_PAYROLL_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_RETAIL_df, on = 'DATE_TIME', how = 'left')\\\n",
    "            .merge(USD_UNEMP_df, on = 'DATE_TIME', how = 'left')\n",
    " \n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  187  overlapping events\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>EX_DATE_TIME</th>\n",
       "      <th>AUD_GDP</th>\n",
       "      <th>AUD_PPI</th>\n",
       "      <th>AUD_RETAILSALES</th>\n",
       "      <th>AUD_UNEMP</th>\n",
       "      <th>AUD_CPI</th>\n",
       "      <th>USD_PPI</th>\n",
       "      <th>USD_CPI</th>\n",
       "      <th>USD_GDP</th>\n",
       "      <th>USD_IR</th>\n",
       "      <th>USD_PAYROLL</th>\n",
       "      <th>USD_RETAIL</th>\n",
       "      <th>USD_UNEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-09 19:30:00</td>\n",
       "      <td>0.99716</td>\n",
       "      <td>0.99661</td>\n",
       "      <td>0.99712</td>\n",
       "      <td>0.99704</td>\n",
       "      <td>2011-01-10 02:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-12 19:30:00</td>\n",
       "      <td>0.99665</td>\n",
       "      <td>0.99451</td>\n",
       "      <td>0.99451</td>\n",
       "      <td>0.99586</td>\n",
       "      <td>2011-01-13 02:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-13 08:30:00</td>\n",
       "      <td>1.00054</td>\n",
       "      <td>0.99878</td>\n",
       "      <td>1.00051</td>\n",
       "      <td>0.99919</td>\n",
       "      <td>2011-01-13 15:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-23 19:30:00</td>\n",
       "      <td>0.98839</td>\n",
       "      <td>0.98720</td>\n",
       "      <td>0.98730</td>\n",
       "      <td>0.98721</td>\n",
       "      <td>2011-01-24 02:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-24 19:30:00</td>\n",
       "      <td>0.99443</td>\n",
       "      <td>0.99380</td>\n",
       "      <td>0.99386</td>\n",
       "      <td>0.99406</td>\n",
       "      <td>2011-01-25 02:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2020-03-11 08:30:00</td>\n",
       "      <td>0.65333</td>\n",
       "      <td>0.65208</td>\n",
       "      <td>0.65278</td>\n",
       "      <td>0.65218</td>\n",
       "      <td>2020-03-11 15:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>2020-03-12 08:30:00</td>\n",
       "      <td>0.63489</td>\n",
       "      <td>0.63363</td>\n",
       "      <td>0.63429</td>\n",
       "      <td>0.63465</td>\n",
       "      <td>2020-03-12 15:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>2020-03-15 17:00:00</td>\n",
       "      <td>0.62280</td>\n",
       "      <td>0.61757</td>\n",
       "      <td>0.62260</td>\n",
       "      <td>0.61761</td>\n",
       "      <td>2020-03-16 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2020-03-17 08:30:00</td>\n",
       "      <td>0.60382</td>\n",
       "      <td>0.60131</td>\n",
       "      <td>0.60150</td>\n",
       "      <td>0.60184</td>\n",
       "      <td>2020-03-17 15:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2020-03-18 20:30:00</td>\n",
       "      <td>0.56977</td>\n",
       "      <td>0.56492</td>\n",
       "      <td>0.56886</td>\n",
       "      <td>0.56580</td>\n",
       "      <td>2020-03-19 03:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>765 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              DATE_TIME     HIGH      LOW     OPEN    CLOSE  \\\n",
       "0   2011-01-09 19:30:00  0.99716  0.99661  0.99712  0.99704   \n",
       "1   2011-01-12 19:30:00  0.99665  0.99451  0.99451  0.99586   \n",
       "2   2011-01-13 08:30:00  1.00054  0.99878  1.00051  0.99919   \n",
       "3   2011-01-23 19:30:00  0.98839  0.98720  0.98730  0.98721   \n",
       "4   2011-01-24 19:30:00  0.99443  0.99380  0.99386  0.99406   \n",
       "..                  ...      ...      ...      ...      ...   \n",
       "760 2020-03-11 08:30:00  0.65333  0.65208  0.65278  0.65218   \n",
       "761 2020-03-12 08:30:00  0.63489  0.63363  0.63429  0.63465   \n",
       "762 2020-03-15 17:00:00  0.62280  0.61757  0.62260  0.61761   \n",
       "763 2020-03-17 08:30:00  0.60382  0.60131  0.60150  0.60184   \n",
       "764 2020-03-18 20:30:00  0.56977  0.56492  0.56886  0.56580   \n",
       "\n",
       "           EX_DATE_TIME  AUD_GDP  AUD_PPI  AUD_RETAILSALES  AUD_UNEMP  \\\n",
       "0   2011-01-10 02:30:00      NaN      NaN              0.3        NaN   \n",
       "1   2011-01-13 02:30:00      NaN      NaN              NaN        5.0   \n",
       "2   2011-01-13 15:30:00      NaN      NaN              NaN        NaN   \n",
       "3   2011-01-24 02:30:00      NaN      0.1              NaN        NaN   \n",
       "4   2011-01-25 02:30:00      NaN      NaN              NaN        NaN   \n",
       "..                  ...      ...      ...              ...        ...   \n",
       "760 2020-03-11 15:30:00      NaN      NaN              NaN        NaN   \n",
       "761 2020-03-12 15:30:00      NaN      NaN              NaN        NaN   \n",
       "762 2020-03-16 00:00:00      NaN      NaN              NaN        NaN   \n",
       "763 2020-03-17 15:30:00      NaN      NaN              NaN        NaN   \n",
       "764 2020-03-19 03:30:00      NaN      NaN              NaN        5.1   \n",
       "\n",
       "     AUD_CPI  USD_PPI  USD_CPI  USD_GDP  USD_IR  USD_PAYROLL  USD_RETAIL  \\\n",
       "0        NaN      NaN      NaN      NaN     NaN          NaN         NaN   \n",
       "1        NaN      NaN      NaN      NaN     NaN          NaN         NaN   \n",
       "2        NaN      1.1      NaN      NaN     NaN          NaN         NaN   \n",
       "3        NaN      NaN      NaN      NaN     NaN          NaN         NaN   \n",
       "4        0.4      NaN      NaN      NaN     NaN          NaN         NaN   \n",
       "..       ...      ...      ...      ...     ...          ...         ...   \n",
       "760      NaN      NaN      0.2      NaN     NaN          NaN         NaN   \n",
       "761      NaN     -0.6      NaN      NaN     NaN          NaN         NaN   \n",
       "762      NaN      NaN      NaN      NaN    0.25          NaN         NaN   \n",
       "763      NaN      NaN      NaN      NaN     NaN          NaN        -0.5   \n",
       "764      NaN      NaN      NaN      NaN     NaN          NaN         NaN   \n",
       "\n",
       "     USD_UNEMP  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "..         ...  \n",
       "760        NaN  \n",
       "761        NaN  \n",
       "762        NaN  \n",
       "763        NaN  \n",
       "764        NaN  \n",
       "\n",
       "[765 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking whether is there any overlapping events in the merged dataframe\n",
    "\n",
    "\n",
    "temp_df = new_df.drop(columns = ['DATE_TIME','HIGH','LOW','OPEN','CLOSE','EX_DATE_TIME']).notnull().sum(axis=1) # A Series of counting number of non 'nan' values accross a row\n",
    "\n",
    "#A function to checking number of overlap events\n",
    "\n",
    "def OverlapCounter(t_df):\n",
    "    count = 0\n",
    "    for i in t_df:\n",
    "        if i>1:\n",
    "            count+=1\n",
    "    print('There are ', count, ' overlapping events')\n",
    "    \n",
    "\n",
    "OverlapCounter(temp_df)# count overlap events\n",
    "\n",
    "t_df = new_df[temp_df==1] #avoid overlapping non event columns\n",
    "df_with_reset_index = t_df.reset_index(drop=True)\n",
    "df_with_reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>Event_value</th>\n",
       "      <th>Event_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-09 19:30:00</td>\n",
       "      <td>0.99716</td>\n",
       "      <td>0.99661</td>\n",
       "      <td>0.99712</td>\n",
       "      <td>0.99704</td>\n",
       "      <td>0.30</td>\n",
       "      <td>AUD_RETAILSALES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-12 19:30:00</td>\n",
       "      <td>0.99665</td>\n",
       "      <td>0.99451</td>\n",
       "      <td>0.99451</td>\n",
       "      <td>0.99586</td>\n",
       "      <td>5.00</td>\n",
       "      <td>AUD_UNEMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-13 08:30:00</td>\n",
       "      <td>1.00054</td>\n",
       "      <td>0.99878</td>\n",
       "      <td>1.00051</td>\n",
       "      <td>0.99919</td>\n",
       "      <td>1.10</td>\n",
       "      <td>USD_PPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-23 19:30:00</td>\n",
       "      <td>0.98839</td>\n",
       "      <td>0.98720</td>\n",
       "      <td>0.98730</td>\n",
       "      <td>0.98721</td>\n",
       "      <td>0.10</td>\n",
       "      <td>AUD_PPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-24 19:30:00</td>\n",
       "      <td>0.99443</td>\n",
       "      <td>0.99380</td>\n",
       "      <td>0.99386</td>\n",
       "      <td>0.99406</td>\n",
       "      <td>0.40</td>\n",
       "      <td>AUD_CPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2020-03-11 08:30:00</td>\n",
       "      <td>0.65333</td>\n",
       "      <td>0.65208</td>\n",
       "      <td>0.65278</td>\n",
       "      <td>0.65218</td>\n",
       "      <td>0.20</td>\n",
       "      <td>USD_CPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>2020-03-12 08:30:00</td>\n",
       "      <td>0.63489</td>\n",
       "      <td>0.63363</td>\n",
       "      <td>0.63429</td>\n",
       "      <td>0.63465</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>USD_PPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>2020-03-15 17:00:00</td>\n",
       "      <td>0.62280</td>\n",
       "      <td>0.61757</td>\n",
       "      <td>0.62260</td>\n",
       "      <td>0.61761</td>\n",
       "      <td>0.25</td>\n",
       "      <td>USD_IR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2020-03-17 08:30:00</td>\n",
       "      <td>0.60382</td>\n",
       "      <td>0.60131</td>\n",
       "      <td>0.60150</td>\n",
       "      <td>0.60184</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>USD_RETAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2020-03-18 20:30:00</td>\n",
       "      <td>0.56977</td>\n",
       "      <td>0.56492</td>\n",
       "      <td>0.56886</td>\n",
       "      <td>0.56580</td>\n",
       "      <td>5.10</td>\n",
       "      <td>AUD_UNEMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>765 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              DATE_TIME     HIGH      LOW     OPEN    CLOSE  Event_value  \\\n",
       "0   2011-01-09 19:30:00  0.99716  0.99661  0.99712  0.99704         0.30   \n",
       "1   2011-01-12 19:30:00  0.99665  0.99451  0.99451  0.99586         5.00   \n",
       "2   2011-01-13 08:30:00  1.00054  0.99878  1.00051  0.99919         1.10   \n",
       "3   2011-01-23 19:30:00  0.98839  0.98720  0.98730  0.98721         0.10   \n",
       "4   2011-01-24 19:30:00  0.99443  0.99380  0.99386  0.99406         0.40   \n",
       "..                  ...      ...      ...      ...      ...          ...   \n",
       "760 2020-03-11 08:30:00  0.65333  0.65208  0.65278  0.65218         0.20   \n",
       "761 2020-03-12 08:30:00  0.63489  0.63363  0.63429  0.63465        -0.60   \n",
       "762 2020-03-15 17:00:00  0.62280  0.61757  0.62260  0.61761         0.25   \n",
       "763 2020-03-17 08:30:00  0.60382  0.60131  0.60150  0.60184        -0.50   \n",
       "764 2020-03-18 20:30:00  0.56977  0.56492  0.56886  0.56580         5.10   \n",
       "\n",
       "          Event_type  \n",
       "0    AUD_RETAILSALES  \n",
       "1          AUD_UNEMP  \n",
       "2            USD_PPI  \n",
       "3            AUD_PPI  \n",
       "4            AUD_CPI  \n",
       "..               ...  \n",
       "760          USD_CPI  \n",
       "761          USD_PPI  \n",
       "762           USD_IR  \n",
       "763       USD_RETAIL  \n",
       "764        AUD_UNEMP  \n",
       "\n",
       "[765 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "x= df_with_reset_index.drop(columns = ['DATE_TIME','HIGH','LOW','OPEN','CLOSE','EX_DATE_TIME'])\n",
    "# collecting the particular event types and thier values according to the date time\n",
    "event_type = []\n",
    "event_values=[]\n",
    "for i in range(len(x)):\n",
    "    for col in x.columns:\n",
    "        val = x.loc[i,col]\n",
    "        if str(val) != 'nan':\n",
    "            event_type.append(col)\n",
    "            \n",
    "            event_values.append(val)\n",
    "            \n",
    "df_with_reset_index['Event_value'] = event_values\n",
    "df_with_reset_index['Event_type'] = event_type \n",
    "\n",
    "# rearrange the data frame by keeping only desired columns\n",
    "train_df = df_with_reset_index[['DATE_TIME','HIGH', 'LOW','OPEN','CLOSE', 'Event_value','Event_type']]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#calculating the trend\n",
    "for i in range(8):\n",
    "    \n",
    "    tempor_df = pd.DataFrame({}) # created a temporary dataframe in order to store shifting dates\n",
    "\n",
    "    tempor_df['DATE_TIME'] = train_df['DATE_TIME'] + pd.Timedelta(minutes=15*(i+1)) #shift the time by 15 minutes of slicers  \n",
    "\n",
    "    x = pd.merge(df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE']],tempor_df, how='right', on='DATE_TIME') # merge the shifted date column and join HIGH, LOW values in the pip data set \n",
    "\n",
    "    x_1 = x['HIGH'].fillna(method = 'bfill') # filling 'nan' values with the next value respected to the 'nan'\n",
    "    x_2 = x['LOW'].fillna(method= 'bfill')\n",
    "    x_3 = x['CLOSE'].fillna(method = 'bfill')\n",
    "    x_4 = x['OPEN'].fillna(method = 'bfill')\n",
    "    \n",
    "    col_name = 'after_'+ str(15*(i+1)) + '_mins'#column names that included (open+close)/2 values 0-120 min in time duration\n",
    "\n",
    "    train_df[col_name] = (x_1 + x_2 + x_3 + x_4)/4\n",
    "       \n",
    "my_df = pd.DataFrame({})\n",
    " \n",
    "init_value = (train_df.iloc[:,1] + train_df.iloc[:,2] + train_df.iloc[:,3] +train_df.iloc[:,4])/4\n",
    "\n",
    "for i in range(8):\n",
    "    col = 'defference of avg from_' + str((i)*15) +'_to_' + str((i+1)*15) \n",
    "     \n",
    "     \n",
    "    my_df[col] = abs(train_df.iloc[:,i+7] - init_value)\n",
    "     \n",
    "    init_value = train_df.iloc[:,i+7]\n",
    "     \n",
    "\n",
    "\n",
    " \n",
    " \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>Event_value</th>\n",
       "      <th>Event_type</th>\n",
       "      <th>Time duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-09 19:30:00</td>\n",
       "      <td>0.99716</td>\n",
       "      <td>0.99661</td>\n",
       "      <td>0.99712</td>\n",
       "      <td>0.99704</td>\n",
       "      <td>0.30</td>\n",
       "      <td>AUD_RETAILSALES</td>\n",
       "      <td>Long term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-12 19:30:00</td>\n",
       "      <td>0.99665</td>\n",
       "      <td>0.99451</td>\n",
       "      <td>0.99451</td>\n",
       "      <td>0.99586</td>\n",
       "      <td>5.00</td>\n",
       "      <td>AUD_UNEMP</td>\n",
       "      <td>Long term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-13 08:30:00</td>\n",
       "      <td>1.00054</td>\n",
       "      <td>0.99878</td>\n",
       "      <td>1.00051</td>\n",
       "      <td>0.99919</td>\n",
       "      <td>1.10</td>\n",
       "      <td>USD_PPI</td>\n",
       "      <td>Short term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-23 19:30:00</td>\n",
       "      <td>0.98839</td>\n",
       "      <td>0.98720</td>\n",
       "      <td>0.98730</td>\n",
       "      <td>0.98721</td>\n",
       "      <td>0.10</td>\n",
       "      <td>AUD_PPI</td>\n",
       "      <td>Long term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-24 19:30:00</td>\n",
       "      <td>0.99443</td>\n",
       "      <td>0.99380</td>\n",
       "      <td>0.99386</td>\n",
       "      <td>0.99406</td>\n",
       "      <td>0.40</td>\n",
       "      <td>AUD_CPI</td>\n",
       "      <td>Short term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2020-03-11 08:30:00</td>\n",
       "      <td>0.65333</td>\n",
       "      <td>0.65208</td>\n",
       "      <td>0.65278</td>\n",
       "      <td>0.65218</td>\n",
       "      <td>0.20</td>\n",
       "      <td>USD_CPI</td>\n",
       "      <td>Long term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>2020-03-12 08:30:00</td>\n",
       "      <td>0.63489</td>\n",
       "      <td>0.63363</td>\n",
       "      <td>0.63429</td>\n",
       "      <td>0.63465</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>USD_PPI</td>\n",
       "      <td>Long term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>2020-03-15 17:00:00</td>\n",
       "      <td>0.62280</td>\n",
       "      <td>0.61757</td>\n",
       "      <td>0.62260</td>\n",
       "      <td>0.61761</td>\n",
       "      <td>0.25</td>\n",
       "      <td>USD_IR</td>\n",
       "      <td>Short term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2020-03-17 08:30:00</td>\n",
       "      <td>0.60382</td>\n",
       "      <td>0.60131</td>\n",
       "      <td>0.60150</td>\n",
       "      <td>0.60184</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>USD_RETAIL</td>\n",
       "      <td>Long term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2020-03-18 20:30:00</td>\n",
       "      <td>0.56977</td>\n",
       "      <td>0.56492</td>\n",
       "      <td>0.56886</td>\n",
       "      <td>0.56580</td>\n",
       "      <td>5.10</td>\n",
       "      <td>AUD_UNEMP</td>\n",
       "      <td>Short term</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>765 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              DATE_TIME     HIGH      LOW     OPEN    CLOSE  Event_value  \\\n",
       "0   2011-01-09 19:30:00  0.99716  0.99661  0.99712  0.99704         0.30   \n",
       "1   2011-01-12 19:30:00  0.99665  0.99451  0.99451  0.99586         5.00   \n",
       "2   2011-01-13 08:30:00  1.00054  0.99878  1.00051  0.99919         1.10   \n",
       "3   2011-01-23 19:30:00  0.98839  0.98720  0.98730  0.98721         0.10   \n",
       "4   2011-01-24 19:30:00  0.99443  0.99380  0.99386  0.99406         0.40   \n",
       "..                  ...      ...      ...      ...      ...          ...   \n",
       "760 2020-03-11 08:30:00  0.65333  0.65208  0.65278  0.65218         0.20   \n",
       "761 2020-03-12 08:30:00  0.63489  0.63363  0.63429  0.63465        -0.60   \n",
       "762 2020-03-15 17:00:00  0.62280  0.61757  0.62260  0.61761         0.25   \n",
       "763 2020-03-17 08:30:00  0.60382  0.60131  0.60150  0.60184        -0.50   \n",
       "764 2020-03-18 20:30:00  0.56977  0.56492  0.56886  0.56580         5.10   \n",
       "\n",
       "          Event_type Time duration  \n",
       "0    AUD_RETAILSALES     Long term  \n",
       "1          AUD_UNEMP     Long term  \n",
       "2            USD_PPI    Short term  \n",
       "3            AUD_PPI     Long term  \n",
       "4            AUD_CPI    Short term  \n",
       "..               ...           ...  \n",
       "760          USD_CPI     Long term  \n",
       "761          USD_PPI     Long term  \n",
       "762           USD_IR    Short term  \n",
       "763       USD_RETAIL     Long term  \n",
       "764        AUD_UNEMP    Short term  \n",
       "\n",
       "[765 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE','Event_value','Event_type']]\n",
    "\n",
    "col = my_df.columns\n",
    "new_s = my_df[col].apply(lambda row: ' '.join(row.values.astype(str)), axis=1) # combine all the values in a row in the train_df into a one string\n",
    "\n",
    "def timeDuration(x):\n",
    "    a = x.split()\n",
    "    l = list(map(float,a))\n",
    "    y = ((l[0]+l[1])/2)*0.75\n",
    "    l.pop(0)\n",
    "    l.pop(0)\n",
    "    l = [x for x in l if x>=y ] \n",
    "    if len(l) >=3:\n",
    "        p = 'Long term'\n",
    "    else:\n",
    "        p= 'Short term'\n",
    "        \n",
    "    return p\n",
    "    \n",
    "train_df['Time duration'] = new_s.apply(lambda x: timeDuration(x))  \n",
    "   \n",
    "train_df  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002305000000002222"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the boundary values fortrend when an event happened\n",
    "def trend(x):\n",
    "    if x == datetime.datetime(2020,3,18,20,30,0):\n",
    "        final = 0\n",
    "    else:\n",
    "        initial_value  =  x - datetime.timedelta(hours= 25)\n",
    "    \n",
    "    \n",
    "        init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "    \n",
    "    \n",
    "        forward_factor = 0\n",
    "        backward_factor = 0\n",
    "    \n",
    "        while len(init_check) != 1:\n",
    "            delta_time = datetime.timedelta(minutes=15)\n",
    "            initial_value = initial_value + delta_time\n",
    "            init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "            forward_factor+= 1\n",
    "     \n",
    "    \n",
    "        initial_value  =  x - datetime.timedelta(hours= 25)\n",
    "        init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "        while len(init_check) !=1:\n",
    "            delta_time = datetime.timedelta(minutes=15)\n",
    "            initial_value = initial_value - delta_time\n",
    "            init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "            backward_factor +=1\n",
    "     \n",
    "     \n",
    "        net_factor = backward_factor + forward_factor \n",
    "        initial_value = initial_value - datetime.timedelta(minutes=15)*(net_factor)\n",
    "     \n",
    "        max_= 0\n",
    "        min_ = 1000\n",
    "        for i in range(99):\n",
    "            time_delta = datetime.timedelta(minutes=15*(99-i))\n",
    "            date = x - time_delta\n",
    "            s = df[df['DATE_TIME']== date]['OPEN']\n",
    "         \n",
    "            if len(s)==1:\n",
    "                date = date\n",
    "        \n",
    "            else:\n",
    "                time_shift = datetime.timedelta(minutes=15)* (net_factor)\n",
    "                date = date - time_shift\n",
    "        \n",
    "        \n",
    "            avg_1 =(df[df['DATE_TIME'] == date ]['OPEN'] + df[df['DATE_TIME']==date ]['CLOSE'])/2   \n",
    "            avg_2 = (df[df['DATE_TIME'] == initial_value ]['OPEN'] + df[df['DATE_TIME']== initial_value ]['CLOSE'])/2     \n",
    "        \n",
    "       \n",
    "        \n",
    "            if len(avg_1) !=1  or len(avg_2) !=1:\n",
    "                val = val\n",
    "        \n",
    "            else:\n",
    "                val = abs(float(avg_1) - float(avg_2))\n",
    "         \n",
    "             \n",
    "        \n",
    "        \n",
    "            if val> max_:\n",
    "                max_=val\n",
    "            else:\n",
    "                max_ = max_\n",
    "            \n",
    "            if val < min_:\n",
    "                min_ = val\n",
    "            else:\n",
    "                min_ = min_\n",
    "        \n",
    "            initial_value = date\n",
    "     \n",
    " \n",
    "     \n",
    "  \n",
    "\n",
    "        initial_value  =  x + datetime.timedelta(hours= 25)\n",
    "    \n",
    "     \n",
    "        init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "    \n",
    "        forward_factor = 0\n",
    "        backward_factor = 0\n",
    "    \n",
    "        while len(init_check) != 1:\n",
    "            delta_time = datetime.timedelta(minutes=15)\n",
    "            initial_value = initial_value + delta_time\n",
    "            init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "            forward_factor+= 1\n",
    "        \n",
    "     \n",
    "    \n",
    "        initial_value  =  x + datetime.timedelta(hours= 25)\n",
    "        init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "    \n",
    "        while len(init_check) !=1:\n",
    "            delta_time = datetime.timedelta(minutes=15)\n",
    "            initial_value = initial_value - delta_time\n",
    "            init_check = df[df['DATE_TIME'] == initial_value]['OPEN']\n",
    "            backward_factor +=1\n",
    "        \n",
    "     \n",
    "     \n",
    "        net_factor = backward_factor + forward_factor\n",
    "        initial_value  =  x + datetime.timedelta(hours= 25) \n",
    "        initial_value = initial_value + datetime.timedelta(minutes=15)*(net_factor)\n",
    "    \n",
    "        for i in range(100):\n",
    "            time_delta = datetime.timedelta(minutes=15*(99-i))\n",
    "            date = x + time_delta\n",
    "            s = df[df['DATE_TIME']== date]['OPEN']\n",
    "        \n",
    "            if len(s)==1:\n",
    "                date = date\n",
    "        \n",
    "            else:\n",
    "                time_shift = datetime.timedelta(minutes=15)* (net_factor)\n",
    "                date = date + time_shift\n",
    "            \n",
    "                \n",
    "            avg_1 =(df[df['DATE_TIME'] == date ]['OPEN'] + df[df['DATE_TIME']==date ]['CLOSE'])/2   \n",
    "            avg_2 = (df[df['DATE_TIME'] == initial_value ]['OPEN'] + df[df['DATE_TIME']== initial_value ]['CLOSE'])/2     \n",
    "         \n",
    "            if len(avg_1) !=1  or len(avg_2) !=1 :\n",
    "                val = val\n",
    "            else:\n",
    "                 val = abs(float(avg_1) - float(avg_2))\n",
    "         \n",
    "            if val> max_:\n",
    "                max_=val\n",
    "            else:\n",
    "                max_ = max_\n",
    "            \n",
    "            if val < min_:\n",
    "                min_ = val\n",
    "            else:\n",
    "                min_ = min_\n",
    "        \n",
    "            initial_value = date\n",
    "        final = min_ + (max_ - min_)*0.10 \n",
    "        \n",
    "    return final   \n",
    "           \n",
    "    \n",
    "         \n",
    "trend(train_df['DATE_TIME'][25] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " \n",
    "train_df['Boundaries'] = train_df['DATE_TIME'].apply(lambda x : trend(x))\n",
    "for i in range(2):\n",
    "    \n",
    "    tempor_df = pd.DataFrame({}) # created a temporary dataframe in order to store shifting dates\n",
    "    \n",
    "    tempor_df['DATE_TIME'] = train_df['DATE_TIME'] - pd.Timedelta(minutes=15*(2-i)) #shift the time by 15 minutes of slicers  \n",
    "\n",
    "    x = pd.merge(df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE']],tempor_df, how='right', on='DATE_TIME') # merge the shifted date column and join HIGH, LOW values in the pip data set \n",
    "\n",
    "    \n",
    "    x_1 = x['CLOSE'].fillna(method = 'bfill')\n",
    "    x_2 = x['OPEN'].fillna(method = 'bfill')\n",
    "    \n",
    "    col_name = '_before'+ str(15*(2-i)) + '_mins' + '_in_trend'#column names that included (open+close)/2 values 0-120 min in time duration\n",
    "\n",
    "    train_df[col_name] = (x_1 + x_2 )/2\n",
    "    \n",
    "for i in range(8):\n",
    "    \n",
    "    tempor_df = pd.DataFrame({}) # created a temporary dataframe in order to store shifting dates\n",
    "\n",
    "    tempor_df['DATE_TIME'] = train_df['DATE_TIME'] + pd.Timedelta(minutes=15*(1+i)) #shift the time by 15 minutes of slicers  \n",
    "\n",
    "    x = pd.merge(df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE']],tempor_df, how='right', on='DATE_TIME') # merge the shifted date column and join HIGH, LOW values in the pip data set \n",
    "\n",
    "    \n",
    "    x_1 = x['CLOSE'].fillna(method = 'bfill')\n",
    "    x_2 = x['OPEN'].fillna(method = 'bfill')\n",
    "    \n",
    "    col_name = '_after'+ str(15*(1+i)) + '_mins' + '_in_trend'#column names that included (open+close)/2 values 0-120 min in time duration\n",
    "\n",
    "    train_df[col_name] = (x_1 + x_2 )/2\n",
    "    \n",
    "train_df\n",
    "my_df = pd.DataFrame({})\n",
    " \n",
    "init_value = (train_df.iloc[:,3] +train_df.iloc[:,4])/2\n",
    "\n",
    "for i in range(8):\n",
    "    col = 'defference of avg in ' +  'slot ' + str(i+1) + ' in trend'\n",
    "     \n",
    "     \n",
    "    my_df[col] = train_df.iloc[:,i+9] - init_value\n",
    "     \n",
    "    init_value = train_df.iloc[:,i+9]  \n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_df\n",
    "trend = []\n",
    "#trend calculation according to the boundaries\n",
    "def final_trend(x):\n",
    "    return {up_count: 'UP' ,down_count: 'DOWN', range_count: 'RANGE'}.get(x)\n",
    "\n",
    "for i in range(len(my_df)):\n",
    "    up_count = 0\n",
    "    down_count = 0\n",
    "    range_count = 0\n",
    "    for col in my_df.columns :\n",
    "        val = my_df.loc[i,col]\n",
    "        lower_boundary = (-1)*(train_df['Boundaries'][i])\n",
    "        upper_boundary = train_df['Boundaries'][i]\n",
    "        if val > upper_boundary:\n",
    "            up_count+=1\n",
    "        elif val< lower_boundary :\n",
    "            down_count+=1\n",
    "        else:\n",
    "            range_count+=1\n",
    "    x = max(up_count,down_count,range_count)\n",
    "    trend.append(final_trend(x))\n",
    "                 \n",
    "train_df['Trend'] = trend\n",
    "     \n",
    "train_df= train_df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE','Event_value','Event_type','Time duration','Trend','Boundaries']]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#calculating the strength when trend = range\n",
    "x= train_df[train_df['Trend']== 'RANGE'].reset_index(drop=True)\n",
    "x['val']=0\n",
    "\n",
    "for i in range(11):\n",
    "    t= pd.DataFrame({})\n",
    "    t['DATE_TIME']= x['DATE_TIME']+pd.Timedelta(minutes = (-45) + (i+1)*15 )\n",
    "    j= pd.merge(df[['DATE_TIME','HIGH','LOW']],t, how='right', on='DATE_TIME')\n",
    "    x_1 = j['HIGH'].fillna(method = 'bfill')\n",
    "    x_2 = j['LOW'].fillna(method = 'bfill')\n",
    "    \n",
    "    val = (x_1 - x_2)/11 #Get the average of high-low \n",
    "    x['val'] = x['val'] + val\n",
    "\n",
    "range_dict = dict(x.groupby('Event_type').val.mean())\n",
    "print(range_dict)\n",
    "count = 0\n",
    "for i in range_dict.values():\n",
    "    range_dict[list(range_dict.keys())[count]] = i/2 # deviding the final value by 2\n",
    "    count+=1\n",
    "range_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#calculating the strength for up trend\n",
    "y= train_df[train_df['Trend']== 'UP'].reset_index(drop=True)\n",
    "y['open_close_avg'] = 0\n",
    "y['high_avg'] = 0\n",
    "for i in range(11):\n",
    "    t= pd.DataFrame({})\n",
    "    t['DATE_TIME']= y['DATE_TIME'] + pd.Timedelta(minutes = (-45) + (i+1)*15 )\n",
    "    k= pd.merge(df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE']],t, how='right', on='DATE_TIME')\n",
    "    y_1 = k['CLOSE'].fillna(method = 'bfill')\n",
    "    y_2 = k['OPEN'].fillna(method = 'bfill')\n",
    "    y_3 = k['HIGH'].fillna(method = 'bfill')\n",
    "    \n",
    "    open_close_avg = (y_1 + y_2)/2\n",
    "    y['high_avg'] = y['high_avg'] +  y_3\n",
    "    y['open_close_avg'] = y['open_close_avg'] + open_close_avg\n",
    "    \n",
    "y['strength'] = (y['high_avg'])/11 - (y['open_close_avg'])/11\n",
    "y= y.set_index('DATE_TIME')\n",
    "    \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#calculating the strength for down trend\n",
    "z= train_df[train_df['Trend']== 'DOWN'].reset_index(drop=True)\n",
    "z['open_close_avg'] = 0\n",
    "z['low_avg'] = 0\n",
    "for i in range(11):\n",
    "    t= pd.DataFrame({})\n",
    "    t['DATE_TIME']= z['DATE_TIME'] + pd.Timedelta(minutes = (-45) + (i+1)*15 )\n",
    "    l= pd.merge(df[['DATE_TIME','HIGH','LOW','OPEN','CLOSE']],t, how='right', on='DATE_TIME')\n",
    "    z_1 = l['CLOSE'].fillna(method = 'bfill')\n",
    "    z_2 = l['OPEN'].fillna(method = 'bfill')\n",
    "    z_3 = l['LOW'].fillna(method = 'bfill')\n",
    "    \n",
    "    open_close_avg = (z_1 + z_2)/2\n",
    "    z['low_avg'] = z['low_avg'] +  z_3\n",
    "    z['open_close_avg'] = z['open_close_avg'] + open_close_avg\n",
    "    \n",
    "z['strength'] = (z['low_avg'])/11 - (z['open_close_avg'])/11\n",
    "z= z.set_index('DATE_TIME') \n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "strength = []\n",
    "\n",
    "for i in range(len(train_df)):\n",
    "    if train_df['Trend'][i] == 'DOWN' :\n",
    "        strength.append(z['strength'][train_df['DATE_TIME'][i]])\n",
    "    elif train_df['Trend'][i] == 'UP' :\n",
    "        strength.append(y['strength'][train_df['DATE_TIME'][i]])\n",
    "     \n",
    "    else :\n",
    "        strength.append(range_dict[train_df['Event_type'][i]])\n",
    "train_df['strength'] = strength\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df['time'] = train_df['DATE_TIME'].dt.time # obtain the particular time from date time and included as a new column to the dataframe\n",
    "train_df['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('AUD-USD train set.csv', encoding = \"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
